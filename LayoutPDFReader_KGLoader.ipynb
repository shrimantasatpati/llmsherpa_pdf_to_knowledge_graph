{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# This is the demo of:\n",
    "#   - using LayoutPDFReader to read PDF files\n",
    "#   - mapping PDF elements into a property graph\n",
    "#   - saving PDF elements into Neo4j\n",
    "#\n",
    "\n",
    "from llmsherpa.readers import LayoutPDFReader\n",
    "\n",
    "llmsherpa_api_url = \"https://readers.llmsherpa.com/api/document/developer/parseDocument?renderFormat=all\"\n",
    "\n",
    "file_location = 'pdf'\n",
    "\n",
    "# References:\n",
    "# https://github.com/Joshua-Yu/graph-rag/blob/main/openai%2Bllmsherpa/LayoutPDFReader_KGLoader.ipynb\n",
    "# https://neo4j.com/developer-blog/graph-llm-rag-application-pdf-documents/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import uuid\n",
    "import hashlib\n",
    "\n",
    "# Please change the following variables to your own Neo4j instance\n",
    "NEO4J_URL = \"bolt://localhost:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"neo4j123456789\"\n",
    "NEO4J_DATABASE = \"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialiseNeo4j():\n",
    "    cypher_schema = [\n",
    "        \"CREATE CONSTRAINT sectionKey IF NOT EXISTS FOR (c:Section) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT chunkKey IF NOT EXISTS FOR (c:Chunk) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT documentKey IF NOT EXISTS FOR (c:Document) REQUIRE (c.url_hash) IS UNIQUE;\",\n",
    "        \"CREATE CONSTRAINT tableKey IF NOT EXISTS FOR (c:Table) REQUIRE (c.key) IS UNIQUE;\",\n",
    "        \"CALL db.index.vector.createNodeIndex('chunkVectorIndex', 'Embedding', 'value', 1536, 'COSINE');\"\n",
    "    ]\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URL, database=NEO4J_DATABASE, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        for cypher in cypher_schema:\n",
    "            session.run(cypher)\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingestDocumentNeo4j(doc, doc_location):\n",
    "\n",
    "\n",
    "    cypher_pool = [\n",
    "        # 0 - Document\n",
    "        \"MERGE (d:Document {url_hash: $doc_url_hash_val}) ON CREATE SET d.url = $doc_url_val RETURN d;\",  \n",
    "        # 1 - Section\n",
    "        \"MERGE (p:Section {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$title_hash_val}) ON CREATE SET p.page_idx = $page_idx_val, p.title_hash = $title_hash_val, p.block_idx = $block_idx_val, p.title = $title_val, p.tag = $tag_val, p.level = $level_val RETURN p;\",\n",
    "        # 2 - Link Section with the Document\n",
    "        \"MATCH (d:Document {url_hash: $doc_url_hash_val}) MATCH (s:Section {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$title_hash_val}) MERGE (d)<-[:HAS_DOCUMENT]-(s);\",\n",
    "        # 3 - Link Section with a parent section\n",
    "        \"MATCH (s1:Section {key: $doc_url_hash_val+'|'+$parent_block_idx_val+'|'+$parent_title_hash_val}) MATCH (s2:Section {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$title_hash_val}) MERGE (s1)<-[:UNDER_SECTION]-(s2);\",\n",
    "        # 4 - Chunk\n",
    "        \"MERGE (c:Chunk {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$sentences_hash_val}) ON CREATE SET c.sentences = $sentences_val, c.sentences_hash = $sentences_hash_val, c.block_idx = $block_idx_val, c.page_idx = $page_idx_val, c.tag = $tag_val, c.level = $level_val RETURN c;\",\n",
    "        # 5 - Link Chunk to Section\n",
    "        \"MATCH (c:Chunk {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$sentences_hash_val}) MATCH (s:Section {key:$doc_url_hash_val+'|'+$parent_block_idx_val+'|'+$parent_hash_val}) MERGE (s)<-[:HAS_PARENT]-(c);\",\n",
    "        # 6 - Table\n",
    "        \"MERGE (t:Table {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$name_val}) ON CREATE SET t.name = $name_val, t.doc_url_hash = $doc_url_hash_val, t.block_idx = $block_idx_val, t.page_idx = $page_idx_val, t.html = $html_val, t.rows = $rows_val RETURN t;\",\n",
    "        # 7 - Link Table to Section\n",
    "        \"MATCH (t:Table {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$name_val}) MATCH (s:Section {key: $doc_url_hash_val+'|'+$parent_block_idx_val+'|'+$parent_hash_val}) MERGE (s)<-[:HAS_PARENT]-(t);\",\n",
    "        # 8 - Link Table to Document if no parent section\n",
    "        \"MATCH (t:Table {key: $doc_url_hash_val+'|'+$block_idx_val+'|'+$name_val}) MATCH (s:Document {url_hash: $doc_url_hash_val}) MERGE (s)<-[:HAS_PARENT]-(t);\"\n",
    "    ]\n",
    "\n",
    "    driver = GraphDatabase.driver(NEO4J_URL, database=NEO4J_DATABASE, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        cypher = \"\"\n",
    "\n",
    "        # 1 - Create Document node\n",
    "        doc_url_val = doc_location\n",
    "        doc_url_hash_val = hashlib.md5(doc_url_val.encode(\"utf-8\")).hexdigest()\n",
    "        print(f\"Ingesting document: {doc_url_val}\")\n",
    "\n",
    "        cypher = cypher_pool[0]\n",
    "        session.run(cypher, doc_url_hash_val=doc_url_hash_val, doc_url_val=doc_url_val)\n",
    "\n",
    "        # 2 - Create Section nodes\n",
    "        \n",
    "        countSection = 0\n",
    "        sections = doc.sections()\n",
    "        print(f\"Number of sections: {len(sections)}\")\n",
    "        for sec in doc.sections():\n",
    "            sec_title_val = sec.title\n",
    "            sec_title_hash_val = hashlib.md5(sec_title_val.encode(\"utf-8\")).hexdigest()\n",
    "            sec_tag_val = sec.tag\n",
    "            sec_level_val = sec.level\n",
    "            sec_page_idx_val = sec.page_idx\n",
    "            sec_block_idx_val = sec.block_idx\n",
    "            print(\"\\n\")\n",
    "            print(f\"Section: {sec_title_val}\")\n",
    "\n",
    "            # MERGE section node\n",
    "            if not sec_tag_val == 'table':\n",
    "                cypher = cypher_pool[1]\n",
    "                session.run(cypher, page_idx_val=sec_page_idx_val\n",
    "                                , title_hash_val=sec_title_hash_val\n",
    "                                , title_val=sec_title_val\n",
    "                                , tag_val=sec_tag_val\n",
    "                                , level_val=sec_level_val\n",
    "                                , block_idx_val=sec_block_idx_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "\n",
    "                # Link Section with a parent section or Document\n",
    "\n",
    "                sec_parent_val = str(sec.parent.to_text())\n",
    "\n",
    "                if sec_parent_val == \"None\":    # use Document as parent\n",
    "\n",
    "                    cypher = cypher_pool[2]\n",
    "                    session.run(cypher, page_idx_val=sec_page_idx_val\n",
    "                                    , title_hash_val=sec_title_hash_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                    , block_idx_val=sec_block_idx_val\n",
    "                                )\n",
    "\n",
    "                else:   # use parent section\n",
    "                    sec_parent_title_hash_val = hashlib.md5(sec_parent_val.encode(\"utf-8\")).hexdigest()\n",
    "                    sec_parent_page_idx_val = sec.parent.page_idx\n",
    "                    sec_parent_block_idx_val = sec.parent.block_idx\n",
    "\n",
    "                    cypher = cypher_pool[3]\n",
    "                    session.run(cypher, page_idx_val=sec_page_idx_val\n",
    "                                    , title_hash_val=sec_title_hash_val\n",
    "                                    , block_idx_val=sec_block_idx_val\n",
    "                                    , parent_page_idx_val=sec_parent_page_idx_val\n",
    "                                    , parent_title_hash_val=sec_parent_title_hash_val\n",
    "                                    , parent_block_idx_val=sec_parent_block_idx_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                )\n",
    "            # **** if sec_parent_val == \"None\":    \n",
    "\n",
    "            countSection += 1\n",
    "        # **** for sec in doc.sections():\n",
    "\n",
    "        \n",
    "        # ------- Continue within the blocks -------\n",
    "        # 3 - Create Chunk nodes from chunks\n",
    "            \n",
    "        countChunk = 0\n",
    "        for chk in doc.chunks():\n",
    "\n",
    "            chunk_block_idx_val = chk.block_idx\n",
    "            chunk_page_idx_val = chk.page_idx\n",
    "            chunk_tag_val = chk.tag\n",
    "            chunk_level_val = chk.level\n",
    "            chunk_sentences = \"\\n\".join(chk.sentences)\n",
    "\n",
    "\n",
    "            # Skip empty chunks\n",
    "            if not chunk_sentences:\n",
    "                continue\n",
    "            print(\"\\n\")\n",
    "            print(f\"Chunk: {chunk_sentences}\")\n",
    "\n",
    "            # MERGE Chunk node\n",
    "            if not chunk_tag_val == 'table':\n",
    "                chunk_sentences_hash_val = hashlib.md5(chunk_sentences.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "                # MERGE chunk node\n",
    "                cypher = cypher_pool[4]\n",
    "                session.run(cypher, sentences_hash_val=chunk_sentences_hash_val\n",
    "                                , sentences_val=chunk_sentences\n",
    "                                , block_idx_val=chunk_block_idx_val\n",
    "                                , page_idx_val=chunk_page_idx_val\n",
    "                                , tag_val=chunk_tag_val\n",
    "                                , level_val=chunk_level_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "            \n",
    "                # Link chunk with a section\n",
    "                # Chunk always has a parent section \n",
    "\n",
    "                chk_parent_val = str(chk.parent.to_text())\n",
    "                \n",
    "                if not chk_parent_val == \"None\":\n",
    "                    chk_parent_hash_val = hashlib.md5(chk_parent_val.encode(\"utf-8\")).hexdigest()\n",
    "                    chk_parent_page_idx_val = chk.parent.page_idx\n",
    "                    chk_parent_block_idx_val = chk.parent.block_idx\n",
    "\n",
    "                    cypher = cypher_pool[5]\n",
    "                    session.run(cypher, sentences_hash_val=chunk_sentences_hash_val\n",
    "                                    , block_idx_val=chunk_block_idx_val\n",
    "                                    , parent_hash_val=chk_parent_hash_val\n",
    "                                    , parent_block_idx_val=chk_parent_block_idx_val\n",
    "                                    , doc_url_hash_val=doc_url_hash_val\n",
    "                                )\n",
    "                    \n",
    "                # Link sentence \n",
    "                #   >> TO DO for smaller token length\n",
    "\n",
    "                countChunk += 1\n",
    "        # **** for chk in doc.chunks(): \n",
    "\n",
    "        # 4 - Create Table nodes\n",
    "\n",
    "        countTable = 0\n",
    "        for tb in doc.tables():\n",
    "            page_idx_val = tb.page_idx\n",
    "            block_idx_val = tb.block_idx\n",
    "            name_val = 'block#' + str(block_idx_val) + '_' + tb.name\n",
    "            html_val = tb.to_html()\n",
    "            rows_val = len(tb.rows)\n",
    "            print(\"\\n\")\n",
    "            print(f\"Table: {name_val}\")\n",
    "\n",
    "            # MERGE table node\n",
    "\n",
    "            cypher = cypher_pool[6]\n",
    "            session.run(cypher, block_idx_val=block_idx_val\n",
    "                            , page_idx_val=page_idx_val\n",
    "                            , name_val=name_val\n",
    "                            , html_val=html_val\n",
    "                            , rows_val=rows_val\n",
    "                            , doc_url_hash_val=doc_url_hash_val\n",
    "                        )\n",
    "            \n",
    "            # Link table with a section\n",
    "            # Table always has a parent section \n",
    "\n",
    "            table_parent_val = str(tb.parent.to_text())\n",
    "            \n",
    "            if not table_parent_val == \"None\":\n",
    "                table_parent_hash_val = hashlib.md5(table_parent_val.encode(\"utf-8\")).hexdigest()\n",
    "                table_parent_page_idx_val = tb.parent.page_idx\n",
    "                table_parent_block_idx_val = tb.parent.block_idx\n",
    "\n",
    "                cypher = cypher_pool[7]\n",
    "                session.run(cypher, name_val=name_val\n",
    "                                , block_idx_val=block_idx_val\n",
    "                                , parent_page_idx_val=table_parent_page_idx_val\n",
    "                                , parent_hash_val=table_parent_hash_val\n",
    "                                , parent_block_idx_val=table_parent_block_idx_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "\n",
    "            else:   # link table to Document\n",
    "                cypher = cypher_pool[8]\n",
    "                session.run(cypher, name_val=name_val\n",
    "                                , block_idx_val=block_idx_val\n",
    "                                , doc_url_hash_val=doc_url_hash_val\n",
    "                            )\n",
    "            countTable += 1\n",
    "\n",
    "        # **** for tb in doc.tables():\n",
    "\n",
    "\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        print(f'\\'{doc_url_val}\\' Done! Summary: ')\n",
    "        print('#Sections: ' + str(countSection))\n",
    "        print('#Chunks: ' + str(countChunk))\n",
    "        print('#Tables: ' + str(countTable))\n",
    "\n",
    "    driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create constraints and indexes\n",
    "\n",
    "# initialiseNeo4j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#PDF files found: 1!\n",
      "Ingesting document: pdf\\09ann.pdf\n",
      "Number of sections: 4\n",
      "\n",
      "\n",
      "Section: Ninety seventh annual report 2003-04\n",
      "\n",
      "\n",
      "Section: Annexure to the Auditors’ Report\n",
      "\n",
      "\n",
      "Section: Ninety seventh annual report 2003-04\n",
      "\n",
      "\n",
      "Section: Mumbai, 20th May, 2004\n",
      "\n",
      "\n",
      "Chunk: (Referred to in paragraph (3) of our report of even date)\n",
      "\n",
      "\n",
      "Chunk: (i) (a) The Company has maintained proper records showing full particulars including quantitative details and situation of fixed assets.\n",
      "\n",
      "\n",
      "Chunk: (ii) (a) The inventory of finished and semi-finished goods and raw materials at Works, Mines and Collieries have been physically verified during the year by the Management.\n",
      "In respect of stores and spare parts and stocks at Stockyards and with Consignment/Conversion Agents, the Company has a programme of verification of stocks over a three-year period.\n",
      "In our opinion, having regard to the nature and location of stocks, the frequency of verification is reasonable.\n",
      "In the case of materials lying with third parties, certificates confirming stocks have been received in respect of a substantial portion of the stocks held.\n",
      "\n",
      "\n",
      "Chunk: (iii) (a) The Company has not taken any loan from any party covered in the register maintained under Section 301 of the Companies Act, 1956.\n",
      "There are six parties covered in the register maintained under Section 301 of the Companies Act, 1956 to whom the Company has granted intercorporate deposits.\n",
      "The maximum amount involved during the year was Rs.\n",
      "232 crores and the year-end balance of intercorporate deposits granted to such parties was Rs.\n",
      "113 crores.\n",
      "\n",
      "\n",
      "Chunk: According to the information and explanations given to us, details of dues of sales tax, customs duty, wealth tax, excise duty and cess which have not been deposited as on 31st March, 2004 on account of any dispute are given below :\n",
      "\n",
      "\n",
      "Chunk: (x) The Company does not have any accumulated losses.\n",
      "The Company has not incurred cash losses during the financial year covered by our audit and the immediately preceding financial year.\n",
      "\n",
      "\n",
      "Chunk: (xi) In our opinion and according to the information and explanations given to us, the Company has not defaulted in repayment of dues to financial institutions, banks or debenture holders.\n",
      "\n",
      "\n",
      "Chunk: (xii) According to the information and explanations given to us, the Company has not granted loans and advances on the basis of security by way of pledge of shares, debentures and other securities.\n",
      "Therefore, the provisions of clause 4(xii) of the Companies (Auditor's Report) Order, 2003 are not applicable to the Company.\n",
      "\n",
      "\n",
      "Chunk: (xiii) In our opinion, the Company is not a chit fund or a nidhi mutual benefit fund/society.\n",
      "Therefore, the provisions of clause 4(xiii) of the Companies (Auditor's Report) Order, 2003 are not applicable to the Company.\n",
      "\n",
      "\n",
      "Chunk: (xiv) In our opinion, the Company is not dealing in or trading in shares, securities, debentures and other investments.\n",
      "Accordingly, the provisions of clause 4(xiv) of the Companies (Auditor's Report) Order, 2003 are not applicable to the Company.\n",
      "\n",
      "\n",
      "Chunk: (xv) In our opinion, the terms and conditions on which the Company has given guarantees for loans taken by others from banks or financial institutions are not prima facie prejudicial to the interest of the Company.\n",
      "\n",
      "\n",
      "Chunk: (xvi) In our opinion, the term loans have been applied for the purpose for which they were raised.\n",
      "\n",
      "\n",
      "Chunk: (xvii) According to the information and explanations given to us and on an overall examination of the Balance Sheet of the Company, we report that no funds raised on short-term basis have been used for long term assets.\n",
      "No long-term funds have been used to finance short-term assets other than temporary deployment in investments pending application.\n",
      "\n",
      "\n",
      "Chunk: (xviii) According to the information and explanations given to us, during the period covered by our audit report, the Company has not made preferential allotment of shares to parties and companies covered in the register maintained under Section 301 of the Companies Act, 1956.\n",
      "\n",
      "\n",
      "Chunk: (xix) According to the information and explanations given to us, the Company has created security in respect of debentures issued.\n",
      "\n",
      "\n",
      "Chunk: (xx) During the period covered by our audit report, the Company has not raised any money by public issues.\n",
      "\n",
      "\n",
      "Chunk: (xxi) To the best of our knowledge and belief and according to the information and explanations given to us, no fraud on or by the Company has been noticed or reported during the course of our audit.\n",
      "\n",
      "\n",
      "Table: block#24_Ninety seventh annual report 2003-04\n",
      "\n",
      "\n",
      "Table: block#57_Ninety seventh annual report 2003-04\n",
      "\n",
      "\n",
      "Table: block#59_Ninety seventh annual report 2003-04\n",
      "\n",
      "\n",
      "'pdf\\09ann.pdf' Done! Summary: \n",
      "#Sections: 4\n",
      "#Chunks: 17\n",
      "#Tables: 3\n",
      "Total time: 0:00:09.971759\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get all documents under the folder\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "pdf_files = glob.glob(file_location + '/*.pdf')\n",
    "\n",
    "print(f'#PDF files found: {len(pdf_files)}!')\n",
    "pdf_reader = LayoutPDFReader(llmsherpa_api_url)\n",
    "\n",
    "# parse documents and create graph\n",
    "startTime = datetime.now()\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    #Reading pdf from path\n",
    "    doc = pdf_reader.read_pdf(pdf_file)\n",
    "\n",
    "    # find the first / in pdf_file from right\n",
    "    idx = pdf_file.rfind('/')\n",
    "    pdf_file_name = pdf_file[idx+1:]\n",
    "\n",
    "    # open a local file to write the JSON\n",
    "    # with open(pdf_file_name + '.json', 'w') as f:\n",
    "    #     # convert doc.json from a list to string\n",
    "    #     f.write(str(doc.json))\n",
    "\n",
    "    ingestDocumentNeo4j(doc, pdf_file)\n",
    "\n",
    "print(f'Total time: {datetime.now() - startTime}')\n",
    "\n",
    "# DONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
